{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esperimenti usati per testare la capacit' dei diversi modelli messi a disposizione da spaCy nella fase di NER e, in particolare, nel riconoscimento di indirizzi. Testiamo spaCy sia in italiano che in inglese usando diversi modelli. \n",
    "\n",
    "Abbiamo notato che, in Italiano, usando i modelli \"standard\" (convolutional), un indirizzo *non* viene identificato a meno che non inizi con una lettera maiuscola, e.g. Via Alessandro Manzoni. Altri problemi sono legati al fatto che non viene individuato l'indirizzo nella sua interezza, e quindi \"Via Alessandro Manzoni, Roma\" viene spezzato in \"Via ALessandro Manzoni\", LOC; e ROMA, LOC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load di un modello spacy\n",
    "import spacy\n",
    "\n",
    "# usually, the model is saved in the nlp object\n",
    "nlp = spacy.load('it_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_on_text(text_, nlp_):\n",
    "    \"\"\"A small method to extract named entities and their labels from a string and print them.\n",
    "    \n",
    "    @param text_ the text to be elaborated\n",
    "    @param nlp_ the spaCy model with the ner component that will do the computation\n",
    "    \"\"\"\n",
    "    doc = nlp_(text_)\n",
    "\n",
    "    # now print the named entities and their labels\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se in italiano, usando il modello it_core_news_lg, che presenta al suo interno una CNN e che è il modello più performante messo a disposizione da spaCy, si elabora una stringa contenente un indirizzo che inizia con lettera maiuscola, il modello lo riconosce correttamente come LOC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mario PER\n",
      "Via Alessandro Manzoni LOC\n",
      "Roma LOC\n"
     ]
    }
   ],
   "source": [
    "# test con \"Via\" in maiuscolo \n",
    "test_text = \"Ciao, sono Mario ed abito in Via Alessandro Manzoni a Roma\"\n",
    "ner_on_text(test_text, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo tuttavia che il numero civico **non** viene riconosciuto come facente parte dell'entità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mario PER\n",
      "Via Alessandro Manzoni LOC\n",
      "Roma LOC\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Ciao, sono Mario ed abito in Via Alessandro Manzoni 6 a Roma\"\n",
    "ner_on_text(test_text, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come dicevamo, se l'indirizzo inizia in minuscola, il modello potrebbe non riconoscere °via° come facente parte dell'indirizzo (sebbene stia riconoscendo Agordat come Località)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciao MISC\n",
      "Marco MISC\n",
      "Agordat LOC\n",
      "Padova LOC\n"
     ]
    }
   ],
   "source": [
    "# test con \"via\" in minuscolo\n",
    "test_text = \"ciao, sono Marco ed abito in via Agordat n. 5, Padova\"\n",
    "ner_on_text(test_text, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando sono presenti nomi di persona o simili nella via, potrebbe succedere che il modello sbagli la classificazione, classificandoli come PER invece che come LOC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marco MISC\n",
      "Piazza Papa Luciani LOC\n",
      "Padova LOC\n",
      "Marco MISC\n",
      "Papa Luciani PER\n",
      "Padova LOC\n"
     ]
    }
   ],
   "source": [
    "# Con Piazza in maiuscolo il modello riconosce correttamente l'indirizzo\n",
    "test_text = \"Ciao, sono Marco ed abito in Piazza Papa Luciani, Padova\"\n",
    "ner_on_text(test_text, nlp)\n",
    "\n",
    "# viceversa, con piazza in minuscolo, il modello lo scambia per una persona\n",
    "test_text = \"Ciao, sono Marco ed abito in piazza Papa Luciani, Padova\"\n",
    "ner_on_text(test_text, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo come qualcosa di simile succeda con i modelli convoluzionali per l'inglese, come vediamo qui di sotto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "# prima importo il modello in inglese\n",
    "nlp_eng = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successivamente, proviamo diversi tipi di indirizzo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alex PERSON\n",
      "10 Downing Street LOC\n",
      "London GPE\n"
     ]
    }
   ],
   "source": [
    "# individua correttamente l'indirizzo. London è identificata come GEP, GEoPolitical entity, non come una LOC generia\n",
    "test_text = \"Hi, I'm Alex and I live in 10 Downing Street, London\"\n",
    "ner_on_text(test_text, nlp_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alex PERSON\n",
      "Sunset Boulevard FAC\n"
     ]
    }
   ],
   "source": [
    "# individua correttamente l'indirizzo. Sunset Boulevard è identificata come FACility\n",
    "test_text = \"Hi, I'm Alex and I live Sunset Boulevard\"\n",
    "ner_on_text(test_text, nlp_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy-transformers in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (1.1.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy-transformers) (2.4.5)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy-transformers) (1.13.0)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.4.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy-transformers) (3.4.3)\n",
      "Requirement already satisfied: transformers<4.22.0,>=3.4.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy-transformers) (4.21.3)\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy-transformers) (0.8.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (4.64.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.28.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.10.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (21.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (0.10.1)\n",
      "Requirement already satisfied: setuptools in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (60.2.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.0.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.0.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.23.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (8.1.5)\n",
      "Requirement already satisfied: jinja2 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (3.1.2)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (0.7.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from torch>=1.6.0->spacy-transformers) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from torch>=1.6.0->spacy-transformers) (8.5.0.96)\n",
      "Requirement already satisfied: typing-extensions in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from torch>=1.6.0->spacy-transformers) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from torch>=1.6.0->spacy-transformers) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from torch>=1.6.0->spacy-transformers) (11.7.99)\n",
      "Requirement already satisfied: wheel in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->spacy-transformers) (0.37.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (0.11.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (0.12.1)\n",
      "Requirement already satisfied: filelock in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from packaging>=20.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.4.0->spacy-transformers) (5.2.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (2.1.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages (from jinja2->spacy<4.0.0,>=3.4.0->spacy-transformers) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddosso/.virtualenvs/NER/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [64], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mpip\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minstall spacy-transformers\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy_transformers\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m nlp_trf\u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39men_core_web_trf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/spacy/__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     39\u001b[0m     \u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m     55\u001b[0m         name,\n\u001b[1;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m     57\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m     58\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m     60\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m     61\u001b[0m     )\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/spacy/util.py:432\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[39mreturn\u001b[39;00m get_lang_class(name\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mblank:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))()\n\u001b[1;32m    431\u001b[0m \u001b[39mif\u001b[39;00m is_package(name):  \u001b[39m# installed as package\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/spacy/util.py:468\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \n\u001b[1;32m    453\u001b[0m \u001b[39mname (str): The package name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[39mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(name)\n\u001b[0;32m--> 468\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mload(vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, enable\u001b[39m=\u001b[39;49menable, exclude\u001b[39m=\u001b[39;49mexclude, config\u001b[39m=\u001b[39;49mconfig)\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/en_core_web_trf/__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides):\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_init_py(\u001b[39m__file__\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moverrides)\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/spacy/util.py:649\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_path\u001b[39m.\u001b[39mexists():\n\u001b[1;32m    648\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE052\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mdata_path))\n\u001b[0;32m--> 649\u001b[0m \u001b[39mreturn\u001b[39;00m load_model_from_path(\n\u001b[1;32m    650\u001b[0m     data_path,\n\u001b[1;32m    651\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m    652\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[1;32m    653\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m    654\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m    655\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m    656\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    657\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/spacy/util.py:506\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    504\u001b[0m overrides \u001b[39m=\u001b[39m dict_to_dot(config)\n\u001b[1;32m    505\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[0;32m--> 506\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(\n\u001b[1;32m    507\u001b[0m     config,\n\u001b[1;32m    508\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m    509\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m    510\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m    511\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m    512\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[1;32m    513\u001b[0m )\n\u001b[1;32m    514\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39mfrom_disk(model_path, exclude\u001b[39m=\u001b[39mexclude, overrides\u001b[39m=\u001b[39moverrides)\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/spacy/util.py:554\u001b[0m, in \u001b[0;36mload_model_from_config\u001b[0;34m(config, meta, vocab, disable, enable, exclude, auto_fill, validate)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[39m# This will automatically handle all codes registered via the languages\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[39m# registry, including custom subclasses provided via entry points\u001b[39;00m\n\u001b[1;32m    553\u001b[0m lang_cls \u001b[39m=\u001b[39m get_lang_class(nlp_config[\u001b[39m\"\u001b[39m\u001b[39mlang\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 554\u001b[0m nlp \u001b[39m=\u001b[39m lang_cls\u001b[39m.\u001b[39;49mfrom_config(\n\u001b[1;32m    555\u001b[0m     config,\n\u001b[1;32m    556\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m    557\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m    558\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m    559\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m    560\u001b[0m     auto_fill\u001b[39m=\u001b[39;49mauto_fill,\n\u001b[1;32m    561\u001b[0m     validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    562\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    564\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/spacy/language.py:1818\u001b[0m, in \u001b[0;36mLanguage.from_config\u001b[0;34m(cls, config, vocab, disable, enable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[1;32m   1815\u001b[0m     factory \u001b[39m=\u001b[39m pipe_cfg\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfactory\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1816\u001b[0m     \u001b[39m# The pipe name (key in the config) here is the unique name\u001b[39;00m\n\u001b[1;32m   1817\u001b[0m     \u001b[39m# of the component, not necessarily the factory\u001b[39;00m\n\u001b[0;32m-> 1818\u001b[0m     nlp\u001b[39m.\u001b[39;49madd_pipe(\n\u001b[1;32m   1819\u001b[0m         factory,\n\u001b[1;32m   1820\u001b[0m         name\u001b[39m=\u001b[39;49mpipe_name,\n\u001b[1;32m   1821\u001b[0m         config\u001b[39m=\u001b[39;49mpipe_cfg,\n\u001b[1;32m   1822\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m   1823\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[1;32m   1824\u001b[0m     )\n\u001b[1;32m   1825\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1826\u001b[0m     \u001b[39m# We need the sourced components to reference the same\u001b[39;00m\n\u001b[1;32m   1827\u001b[0m     \u001b[39m# vocab without modifying the current vocab state **AND**\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[39m# during deserialization, so they do not need any\u001b[39;00m\n\u001b[1;32m   1833\u001b[0m     \u001b[39m# additional handling.\u001b[39;00m\n\u001b[1;32m   1834\u001b[0m     \u001b[39mif\u001b[39;00m vocab_b \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/spacy/language.py:801\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_factory(factory_name):\n\u001b[1;32m    794\u001b[0m         err \u001b[39m=\u001b[39m Errors\u001b[39m.\u001b[39mE002\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    795\u001b[0m             name\u001b[39m=\u001b[39mfactory_name,\n\u001b[1;32m    796\u001b[0m             opts\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactory_names),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    799\u001b[0m             lang_code\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlang,\n\u001b[1;32m    800\u001b[0m         )\n\u001b[0;32m--> 801\u001b[0m     pipe_component \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_pipe(\n\u001b[1;32m    802\u001b[0m         factory_name,\n\u001b[1;32m    803\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    804\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    805\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[1;32m    806\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    807\u001b[0m     )\n\u001b[1;32m    808\u001b[0m pipe_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_pipe_index(before, after, first, last)\n\u001b[1;32m    809\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_meta[name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/spacy/language.py:680\u001b[0m, in \u001b[0;36mLanguage.create_pipe\u001b[0;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    677\u001b[0m cfg \u001b[39m=\u001b[39m {factory_name: config}\n\u001b[1;32m    678\u001b[0m \u001b[39m# We're calling the internal _fill here to avoid constructing the\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[39m# registered functions twice\u001b[39;00m\n\u001b[0;32m--> 680\u001b[0m resolved \u001b[39m=\u001b[39m registry\u001b[39m.\u001b[39;49mresolve(cfg, validate\u001b[39m=\u001b[39;49mvalidate)\n\u001b[1;32m    681\u001b[0m filled \u001b[39m=\u001b[39m registry\u001b[39m.\u001b[39mfill({\u001b[39m\"\u001b[39m\u001b[39mcfg\u001b[39m\u001b[39m\"\u001b[39m: cfg[factory_name]}, validate\u001b[39m=\u001b[39mvalidate)[\u001b[39m\"\u001b[39m\u001b[39mcfg\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    682\u001b[0m filled \u001b[39m=\u001b[39m Config(filled)\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/confection/__init__.py:728\u001b[0m, in \u001b[0;36mregistry.resolve\u001b[0;34m(cls, config, schema, overrides, validate)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    720\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresolve\u001b[39m(\n\u001b[1;32m    721\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    726\u001b[0m     validate: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    727\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m--> 728\u001b[0m     resolved, _ \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_make(\n\u001b[1;32m    729\u001b[0m         config, schema\u001b[39m=\u001b[39;49mschema, overrides\u001b[39m=\u001b[39;49moverrides, validate\u001b[39m=\u001b[39;49mvalidate, resolve\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    730\u001b[0m     )\n\u001b[1;32m    731\u001b[0m     \u001b[39mreturn\u001b[39;00m resolved\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/confection/__init__.py:777\u001b[0m, in \u001b[0;36mregistry._make\u001b[0;34m(cls, config, schema, overrides, resolve, validate)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_interpolated:\n\u001b[1;32m    776\u001b[0m     config \u001b[39m=\u001b[39m Config(orig_config)\u001b[39m.\u001b[39minterpolate()\n\u001b[0;32m--> 777\u001b[0m filled, _, resolved \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_fill(\n\u001b[1;32m    778\u001b[0m     config, schema, validate\u001b[39m=\u001b[39;49mvalidate, overrides\u001b[39m=\u001b[39;49moverrides, resolve\u001b[39m=\u001b[39;49mresolve\n\u001b[1;32m    779\u001b[0m )\n\u001b[1;32m    780\u001b[0m filled \u001b[39m=\u001b[39m Config(filled, section_order\u001b[39m=\u001b[39msection_order)\n\u001b[1;32m    781\u001b[0m \u001b[39m# Check that overrides didn't include invalid properties not in config\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/confection/__init__.py:832\u001b[0m, in \u001b[0;36mregistry._fill\u001b[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[1;32m    830\u001b[0m     schema\u001b[39m.\u001b[39m__fields__[key] \u001b[39m=\u001b[39m copy_model_field(field, Any)\n\u001b[1;32m    831\u001b[0m promise_schema \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmake_promise_schema(value, resolve\u001b[39m=\u001b[39mresolve)\n\u001b[0;32m--> 832\u001b[0m filled[key], validation[v_key], final[key] \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_fill(\n\u001b[1;32m    833\u001b[0m     value,\n\u001b[1;32m    834\u001b[0m     promise_schema,\n\u001b[1;32m    835\u001b[0m     validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    836\u001b[0m     resolve\u001b[39m=\u001b[39;49mresolve,\n\u001b[1;32m    837\u001b[0m     parent\u001b[39m=\u001b[39;49mkey_parent,\n\u001b[1;32m    838\u001b[0m     overrides\u001b[39m=\u001b[39;49moverrides,\n\u001b[1;32m    839\u001b[0m )\n\u001b[1;32m    840\u001b[0m reg_name, func_name \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_constructor(final[key])\n\u001b[1;32m    841\u001b[0m args, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mparse_args(final[key])\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/confection/__init__.py:849\u001b[0m, in \u001b[0;36mregistry._fill\u001b[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[1;32m    846\u001b[0m     getter \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget(reg_name, func_name)\n\u001b[1;32m    847\u001b[0m     \u001b[39m# We don't want to try/except this and raise our own error\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     \u001b[39m# here, because we want the traceback if the function fails.\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m     getter_result \u001b[39m=\u001b[39m getter(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    850\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     \u001b[39m# We're not resolving and calling the function, so replace\u001b[39;00m\n\u001b[1;32m    852\u001b[0m     \u001b[39m# the getter_result with a Promise class\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     getter_result \u001b[39m=\u001b[39m Promise(\n\u001b[1;32m    854\u001b[0m         registry\u001b[39m=\u001b[39mreg_name, name\u001b[39m=\u001b[39mfunc_name, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    855\u001b[0m     )\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/spacy_transformers/architectures.py:234\u001b[0m, in \u001b[0;36mcreate_TransformerModel_v3\u001b[0;34m(name, get_spans, tokenizer_config, transformer_config, mixed_precision, grad_scaler_config)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m@registry\u001b[39m\u001b[39m.\u001b[39marchitectures\u001b[39m.\u001b[39mregister(\u001b[39m\"\u001b[39m\u001b[39mspacy-transformers.TransformerModel.v3\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_TransformerModel_v3\u001b[39m(\n\u001b[1;32m    201\u001b[0m     name: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m     grad_scaler_config: \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m {},\n\u001b[1;32m    207\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Model[List[Doc], \u001b[39m\"\u001b[39m\u001b[39mFullTransformerBatch\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    208\u001b[0m     \u001b[39m\"\"\"Pretrained transformer model that can be finetuned for downstream tasks.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[39m    name (str): Name of the pretrained Huggingface model to use.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39m        `growth_interval` steps.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     model \u001b[39m=\u001b[39m TransformerModel(\n\u001b[1;32m    235\u001b[0m         name,\n\u001b[1;32m    236\u001b[0m         get_spans,\n\u001b[1;32m    237\u001b[0m         tokenizer_config,\n\u001b[1;32m    238\u001b[0m         transformer_config,\n\u001b[1;32m    239\u001b[0m         mixed_precision,\n\u001b[1;32m    240\u001b[0m         grad_scaler_config,\n\u001b[1;32m    241\u001b[0m     )\n\u001b[1;32m    242\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/spacy_transformers/layers/transformer_model.py:45\u001b[0m, in \u001b[0;36mTransformerModel.__init__\u001b[0;34m(self, name, get_spans, tokenizer_config, transformer_config, mixed_precision, grad_scaler_config)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mget_spans (Callable[[List[Doc]], List[Span]]):\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m    A function to extract spans from the batch of Doc objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mtransformer_config (dict): Settings to pass to the transformers forward pass.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m hf_model \u001b[39m=\u001b[39m HFObjects(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, tokenizer_config, transformer_config)\n\u001b[0;32m---> 45\u001b[0m wrapper \u001b[39m=\u001b[39m HFWrapper(\n\u001b[1;32m     46\u001b[0m     hf_model,\n\u001b[1;32m     47\u001b[0m     convert_inputs\u001b[39m=\u001b[39;49m_convert_transformer_inputs,\n\u001b[1;32m     48\u001b[0m     convert_outputs\u001b[39m=\u001b[39;49m_convert_transformer_outputs,\n\u001b[1;32m     49\u001b[0m     mixed_precision\u001b[39m=\u001b[39;49mmixed_precision,\n\u001b[1;32m     50\u001b[0m     grad_scaler_config\u001b[39m=\u001b[39;49mgrad_scaler_config,\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     52\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m     53\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtransformer\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m     forward,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     },\n\u001b[1;32m     67\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/spacy_transformers/layers/hf_wrapper.py:53\u001b[0m, in \u001b[0;36mHFWrapper\u001b[0;34m(hf_model, convert_inputs, convert_outputs, mixed_precision, grad_scaler_config, config_cls, model_cls, tokenizer_cls)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mif\u001b[39;00m convert_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     convert_outputs \u001b[39m=\u001b[39m convert_pytorch_default_outputs\n\u001b[1;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m Model(\n\u001b[1;32m     49\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhf-pytorch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     50\u001b[0m     pt_forward,\n\u001b[1;32m     51\u001b[0m     attrs\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mconvert_inputs\u001b[39m\u001b[39m\"\u001b[39m: convert_inputs, \u001b[39m\"\u001b[39m\u001b[39mconvert_outputs\u001b[39m\u001b[39m\"\u001b[39m: convert_outputs},\n\u001b[1;32m     52\u001b[0m     shims\u001b[39m=\u001b[39m[\n\u001b[0;32m---> 53\u001b[0m         HFShim(\n\u001b[1;32m     54\u001b[0m             hf_model,\n\u001b[1;32m     55\u001b[0m             mixed_precision\u001b[39m=\u001b[39;49mmixed_precision,\n\u001b[1;32m     56\u001b[0m             grad_scaler_config\u001b[39m=\u001b[39;49mgrad_scaler_config,\n\u001b[1;32m     57\u001b[0m             config_cls\u001b[39m=\u001b[39;49mconfig_cls,\n\u001b[1;32m     58\u001b[0m             model_cls\u001b[39m=\u001b[39;49mmodel_cls,\n\u001b[1;32m     59\u001b[0m             tokenizer_cls\u001b[39m=\u001b[39;49mtokenizer_cls,\n\u001b[1;32m     60\u001b[0m         )\n\u001b[1;32m     61\u001b[0m     ],\n\u001b[1;32m     62\u001b[0m     dims\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mnI\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mnO\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mNone\u001b[39;00m},\n\u001b[1;32m     63\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/spacy_transformers/layers/hf_shim.py:46\u001b[0m, in \u001b[0;36mHFShim.__init__\u001b[0;34m(self, model, config, optimizer, mixed_precision, grad_scaler_config, config_cls, model_cls, tokenizer_cls)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39menabled\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m grad_scaler_config:\n\u001b[1;32m     39\u001b[0m     grad_scaler_config[\u001b[39m\"\u001b[39m\u001b[39menabled\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m mixed_precision\n\u001b[1;32m     41\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m     42\u001b[0m     model\u001b[39m.\u001b[39mtransformer,\n\u001b[1;32m     43\u001b[0m     config,\n\u001b[1;32m     44\u001b[0m     optimizer,\n\u001b[1;32m     45\u001b[0m     mixed_precision,\n\u001b[0;32m---> 46\u001b[0m     grad_scaler\u001b[39m=\u001b[39mPyTorchGradScaler(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgrad_scaler_config),\n\u001b[1;32m     47\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/NER/lib/python3.8/site-packages/thinc/shims/pytorch_grad_scaler.py:54\u001b[0m, in \u001b[0;36mPyTorchGradScaler.__init__\u001b[0;34m(self, enabled, init_scale, backoff_factor, growth_factor, growth_interval)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backoff_factor \u001b[39m=\u001b[39m backoff_factor\n\u001b[1;32m     52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_growth_interval \u001b[39m=\u001b[39m growth_interval\n\u001b[0;32m---> 54\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_growth_tracker \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfull((\u001b[39m1\u001b[39m,), \u001b[39m0\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint)\n\u001b[1;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scale \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfull((\u001b[39m1\u001b[39m,), init_scale)\n\u001b[1;32m     56\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_found_inf \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'full'"
     ]
    }
   ],
   "source": [
    "# proviamo con transformers invece\n",
    "# %pip install spacy-transformers\n",
    "\n",
    "import spacy_transformers\n",
    "\n",
    "nlp_trf= spacy.load('en_core_web_trf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('NER')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e92c8a08333f1ec85557c60f46a2c9c6f09b9867acc2a37086294b24343c3efc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
